---
title: 'Twist 2018: Airtraffic challenge'
output:
 prettydoc::html_pretty:
   theme: cayman
   highlight: github
   toc: true
   number_sections: true
   df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, fig.align = "center", fig.height = 6)
```

# Libraries and data
```{r}
rm(list = ls())
library(tidyverse)
library(lubridate)
library(gridExtra)
library(ggfortify)
```

```{r}
# flightdata <- readRDS("twist_zrh/twist_zrh.RDS")
# 
# fac2num <- function(x) as.numeric(as.character(x))
# flightdata <- flightdata %>%
#   mutate(date = as.Date(flightdata$date, "%d.%m.%Y")) %>%
#   mutate_at(vars(lightnings_hour_n, lightnings_hour_f,
#                  winddir_h, windspeed_avg_h, windspeed_peak_h,
#                  global_rad_avg_h, global_rad_avg_h, airpres,
#                  sunshine_dur_min, temp_avg, temp_min,
#                  temp_max, rel_humid, precip), fac2num)
# glimpse(flightdata)
# write_rds(flightdata, "twist_zrh_cleaned.RDS")
flightdata <- readRDS("twist_zrh_cleaned.RDS")
flightdata <- na.omit(flightdata)

flightdata <- flightdata %>%
  mutate(month = month(date),
         hour = hour(planed_time),
         continent = as.character(continent)) %>%
  mutate(month = as.factor(month),
         hour = as.factor(hour),
         continent = as.factor(continent))
glimpse(flightdata)

flightdata <- flightdata %>%
  mutate(delayed = ifelse(abs(as.numeric(diff_in_secs)) > 1800, 1, 0))
flightdata_landing <- flightdata %>%
  filter(start_landing == "L")
flightdata_starting <- flightdata %>%
  filter(start_landing == "S")
```

## Standardize some of the variables for numerial reasons
```{r}
flightdata_stand <- flightdata %>%
  mutate_at(funs(scale(.) %>% as.vector), 
               .vars = c("distance_km","windspeed_avg_h", "rel_humid",
                      "lightnings_hour_n", "lightnings_hour_f", "temp_max",
                      "sunshine_dur_min", "airpres", "global_rad_avg_h",
                      "precip", "windspeed_peak_h"))
flightdata_stand_starting <- flightdata_stand %>%
  filter(start_landing == "S")
```

# EDA visualization
## Looking at time difference distribution
```{r}
plot_all <- flightdata %>%
  ggplot(aes(x = diff_in_secs)) + 
    geom_histogram(bins = 60, col = 1) +
    labs(title = "starting flights: full dataset") +
    facet_wrap(~ start_landing)

plot_withoutoutliers <- flightdata %>%
  filter(abs(diff_in_secs) < 10000) %>%
  ggplot(aes(x = diff_in_secs)) + 
    geom_histogram(bins = 60, col = 1) +
    labs(title = "absolute difference < 10000") +
    facet_wrap(~ start_landing)

grid.arrange(plot_all, plot_withoutoutliers, ncol = 2)
```

The *distribution of the difference* in seconds has many extreme values and also seems to be skewed. As expected the difference in seconds is more skewed for starting flights than for landing flights.


## Boxplots for different months and hours of the day
```{r}
flightdata %>%
  filter(abs(diff_in_secs) < 5000) %>%
  ggplot(aes(x = month, y = as.numeric(diff_in_secs))) + 
    geom_boxplot() +
    facet_wrap(~ start_landing)
flightdata %>%
  filter(abs(diff_in_secs) < 5000) %>%
  ggplot(aes(x = hour, y = as.numeric(diff_in_secs))) + 
    geom_boxplot() +
    facet_wrap(~ start_landing)
```

Looking at the distribution of the difference in seconds for the different *months* over the year, one can clearly see that there are some seasonal patterns. The summer and winter holiday seasons are associated with higher difference in seconds.

Similar periodic patterns are visibile when looking at the the distribution of the difference in seconds at the different *hours* of the day. More delays occur in the morning compared to lunchtime, the afternoon, and in the evening.


## Comparing Schengen to non-Schengen
```{r}
flightdata %>%
  ggplot(aes(x = schengen, y = as.numeric(diff_in_secs))) +
    geom_boxplot() +
    facet_wrap(~ start_landing) +
    ylim(-5000, 5000) +
    labs(y = "Difference in seconds")
```

Visually there is no difference in the distribution of the difference in seconds visible *comparing Schengen to Non-Schengen* flights.

## Airlines and airplane types
```{r fig.height = 10}
flightdata %>%
  arrange(airline_name) %>%
  group_by(airline_name) %>%
  filter(n() > 1000) %>%
  ggplot(aes(x = airline_name, y = as.numeric(diff_in_secs), 
                         group = airline_name)) +
    geom_boxplot() +
    geom_hline(yintercept = 0, col = 4) +
    facet_wrap(~ start_landing) + 
    ylim(-5000, 10000) +
    coord_flip() +
    labs(x = "Airline name", y = "Difference in seconds", 
         title = "Airlines with more than 1000 flights")

flightdata %>%
  arrange(airplane_type) %>%
  group_by(airplane_type) %>%
  filter(n() > 100) %>%
  ggplot(aes(x = airplane_type, y = as.numeric(diff_in_secs), 
                         group = airplane_type)) +
    geom_boxplot() +
    geom_hline(yintercept = 0, col = 4) +
    facet_wrap(~ start_landing) +
    ylim(-5000, 10000) +
    coord_flip() +
    labs(x = "Airplane type", y = "Difference in seconds", 
         title = "Airplane types with more than 100 flights")
```

Looking at the difference in seconds distributions conditioned on the different *airlines*, it's clearly visible that some of them have more and longer delays than others. Thinking about possible explanations for the more frequent delays of different airlines we hypothesize that low-cost airlines (e.g. Air Berlin) try to minimize the time on the ground because of monetary reasons. Also we think that higher security standards could explain the more frequent delays of other airlines (e.g. El Al Israel).

Also visually visible are delay differences between the *different airplane* types. We hypothesize that the airlines have different airplane fleets and therefore some airplane types are not uniformly represented over all airlines. That's why we think that the delays associated with certain airlines propogate to the airplane types. 


## Correlations between different quantitative covariates
```{r}
library(ggcorrplot)
num_cov <- flightdata[,c("temp_avg", "temp_min", "temp_max", 
                      "sunshine_dur_min","global_rad_avg_h", "precip", "winddir_h",
                      "windspeed_avg_h", "windspeed_peak_h", "airpres","rel_humid",
                      "lightnings_hour_n", "lightnings_hour_f")]
corr <- round(cor(num_cov, use = "complete.obs"), 2)
ggcorrplot(corr)
```

When looking at the *correlation between quantitative covariates*, it's visible that some of them are strongly correlated. A possibility to deal with this would be to use dimension reduction techniques such as principal component analysis. Unfortunately, we checked this only when we didn't have enough time anymore to that.


# Modeling
## Linear model with quantiative covariates  
```{r}
model1 <- as.formula(as.numeric(diff_in_secs) ~ distance_km + windspeed_avg_h
                     + temp_avg + rel_humid + lightnings_hour_n + lightnings_hour_f
                     + sunshine_dur_min + airpres + global_rad_avg_h)
fit1 <- lm(model1, flightdata_starting)
summary(fit1)
autoplot(fit1)
```

When fitting a multiple linear regression model with some of the quantitative variables and looking at the model diagnostics, we can see that the residual distribution has extremely long tails and is clearly not Gaussian. Therefore, our model assumptions are violated. This is probably due to the many extreme observations which we are not able to capture with our model. At a later point we tried to exclude some of the extreme values and fit a linear model on the remaining data (see further below).


## Best subset model selection with BIC criterion  
```{r}
library(leaps)
modelall <- as.formula(as.numeric(diff_in_secs) ~ distance_km + windspeed_avg_h
                     + temp_avg + rel_humid + lightnings_hour_n + lightnings_hour_f
                     + sunshine_dur_min + airpres + global_rad_avg_h + temp_max
                     + temp_min + precip + windspeed_peak_h + windspeed_peak_h)
modelselection <- regsubsets(modelall, data = flightdata_starting, nvmax = 14)
minmodel <- which.min(summary(modelselection)$bic)
bestmodel <- as.formula(paste(c("as.numeric(diff_in_secs) ~ ", 
                                paste(names(coef(modelselection, minmodel)[-1]), 
                                      collapse = "+")), collapse = ""))
bestfit <- lm(bestmodel, flightdata_starting)
summary(bestfit)
autoplot(bestfit)
```

I also used an exhaustive search algorithm the select the model with the quantitative covariates that reduce the BIC criterion the most. This model included almost all of the quantitative covariates and $R^2$ didn't improve much (was still very low), also the diagnostics indicate a very bad model fit.


## Adding months and hours to models
```{r}
bestmodel_withtime <- update(bestmodel, . ~ . + month + hour)
fit_time <- lm(bestmodel_withtime, flightdata_starting)
summary(fit_time)
autoplot(fit_time)
```

To capture time trends, we introduced the month and hour covariates to the models which could improve the model fit in the linear model.

## Excluding extreme values and using linear model
```{r}
flightdata_starting_withoutoutliers <- flightdata_starting %>%
  filter(abs(as.numeric(diff_in_secs)) < 5000)
fit_linear_withoutoutliers <- lm(bestmodel_withtime, flightdata_starting)
summary(fit_linear_withoutoutliers)
autoplot(fit_linear_withoutoutliers)
```

Also when dropping the extreme values, the residual distribution didn't become Gaussian.


## Logistic regression model using delay > 30 min as outcome
```{r}
model_glm <- as.formula(delayed ~ distance_km + windspeed_avg_h + schengen
                     + temp_avg + rel_humid + lightnings_hour_n + lightnings_hour_f
                     + sunshine_dur_min + airpres + global_rad_avg_h + temp_max
                     + temp_min + precip + windspeed_peak_h + windspeed_peak_h)
fit_glm1 <- glm(model_glm, data = flightdata_stand_starting, family = "binomial")
summary(fit_glm1)

# missclassification
mean(flightdata_starting$delayed != as.numeric(predict(fit_glm1, type = "response") > 0.5))
```

We then decided to use a different approach and categorize the difference in seconds variable as delayed when the difference was larger than 30 minutes, and as not delayed otherwise. Then we used a logistic regression model to model the probability of a delay. We achieved a training-missclassification rate of around 10 percent.

```{r}
glm_month <- as.formula(delayed ~ distance_km + windspeed_avg_h + schengen
                     + temp_avg + rel_humid + lightnings_hour_n + lightnings_hour_f
                     + sunshine_dur_min + airpres + global_rad_avg_h + temp_max
                     + temp_min + precip + windspeed_peak_h + month)
fit_glm_month <- glm(glm_month, data = flightdata_stand_starting, family = "binomial")
summary(fit_glm_month)
mean(flightdata_starting$delayed != as.numeric(predict(fit_glm_month, type = "response") > 0.5))

glm_month_hour <- as.formula(delayed ~ distance_km + windspeed_avg_h + schengen
                     + temp_avg + rel_humid + lightnings_hour_n + lightnings_hour_f
                     + sunshine_dur_min + airpres + global_rad_avg_h + temp_max
                     + temp_min + precip + windspeed_peak_h + month + hour)
fit_glm_month_hour <- glm(glm_month_hour, data = flightdata_stand_starting, family = "binomial")
summary(fit_glm_month_hour)
mean(flightdata_starting$delayed != as.numeric(predict(fit_glm_month_hour, type = "response") > 0.5))

anova(fit_glm1, fit_glm_month, fit_glm_month_hour, test = "LR")
```

The missclassification rate didn't change when adding month and hour covariates, but difference in the residual deviance was significantly different when testing with a likelhood ratio test.

## Getting cross-validation missclassification rate
```{r}
set.seed(123)
Kfold_cv_glm <- function(model_form, data, K){
  n <- nrow(data)
  ind_permuted <- sample(n, n, replace = FALSE)
  folds <- cut(ind_permuted, K, labels = FALSE)
  missclass <- sapply(seq(2), function(k){
    train <- which(folds != k)
    fit <- glm(model_form, data = data[train,], family = "binomial")
    mean(data$delayed[-train] != as.numeric(predict(fit, newdata = data[-train,], type = "response") > 0.5))
  })
  return(missclass)
}
missclassification_cv <- Kfold_cv_glm(glm_month_hour, flightdata_stand_starting, 10)
mean(missclassification_cv)
```

I then tried to evaluate the logistic regression model with 10-fold crossvalidation which resulted in a similar missclassification rate of around 10 percent. 


## Plotting model predictions (probability scale)
```{r fig.height = 5}
library(visreg)
distance <- visreg(fit_glm_month_hour, "distance_km", scale = "response", gg = TRUE) + ylim(0, 0.6)
windspeed <- visreg(fit_glm_month_hour, "windspeed_avg_h", scale = "response", gg = TRUE) + ylim(0, 0.6)
airpressure <- visreg(fit_glm_month_hour, "airpres", scale = "response", gg = TRUE) + ylim(0, 0.6)
lightning <- visreg(fit_glm_month_hour, "lightnings_hour_f", scale = "response", gg = TRUE) + ylim(0, 0.6)
grid.arrange(distance, windspeed, airpressure, lightning, ncol = 2)

sunshine <- visreg(fit_glm_month_hour, "sunshine_dur_min", scale = "response", gg = TRUE) + ylim(0, 0.6)
windspeed <- visreg(fit_glm_month_hour, "windspeed_avg_h", scale = "response", gg = TRUE) + ylim(0, 0.6)
global_radiation <- visreg(fit_glm_month_hour, "global_rad_avg_h", scale = "response", gg = TRUE) + ylim(0, 0.6)
months <- visreg(fit_glm_month_hour, "month", scale = "response", gg = TRUE) + ylim(0, 0.6)
grid.arrange(sunshine, windspeed, global_radiation, months, ncol = 2)

hours <- visreg(fit_glm_month_hour, "hour", scale = "response", gg = TRUE) + ylim(0, 0.6)
precip <- visreg(fit_glm_month_hour, "precip", scale = "response", gg = TRUE) + ylim(0, 0.6)
lightnings_hour_n <- visreg(fit_glm_month_hour, "lightnings_hour_n", scale = "response", gg = TRUE) + ylim(0, 0.6)
rel_humid <- visreg(fit_glm_month_hour, "rel_humid", scale = "response", gg = TRUE) + ylim(0, 0.6)
grid.arrange(hours, precip, lightnings_hour_n, rel_humid, ncol = 2)
```

Since we only used additive effects and no interactions in the model, we are able to look at the model predicitions of one covariate when keeping the other variables fixed (here at their median value, respectively their most common category).
    - Higher flight distance is associated with lower delay probability
    - Higher windspeends are associated with higher delay probability
    - More lightnings far away are associated with higher delay probability
    - Higher airpressure is associated with lower delay probability
    - There is are seasonal patterns. The closer to the holidays the higher the delay probability
    - Flights in the morning are associated with less delay probability than 
    - More lightnings nearby are associated with lower delay probability
    - More relative humidity is associated with higher delay probability. This is counterintuitive and we don't really have an explanation.


## Logistic regression model with random effects for airline and airplane type
```{r}
# library(lme4)
glm_mixed <- as.formula(delayed ~ distance_km + windspeed_avg_h + schengen
                        + rel_humid + lightnings_hour_n + lightnings_hour_f
                        + sunshine_dur_min + airpres + global_rad_avg_h + temp_max
                        + precip + windspeed_peak_h + month + hour
                        + (1|airline_name) + (1|airplane_type))
# fit_glm_mixed <- glmer(glm_mixed, data = flightdata_starting, family = "binomial", nAGQ = 1)
```

We tried to fit a mixed logistic regression model with random intercepts for airline and airplane types, but the optimization ran into numerical issues.

## Bayesian logistic regression model with lasso prior
```{r}
library(brms)
glm_bayes <- as.formula(delayed ~ distance_km + windspeed_avg_h + schengen
                        + rel_humid + lightnings_hour_n + lightnings_hour_f
                        + sunshine_dur_min + airpres + global_rad_avg_h + temp_max
                        + precip + windspeed_peak_h + month + hour)
# bayes_glm <- brm(glm_bayes, data = flightdata_stand_starting, family = "bernoulli",
#                  prior = set_prior(lasso(df = 1, scale = 1)))
# save(bayes_glm, file = "bayes_glm_fit.RData")
load("bayes_glm_fit.RData")
bayes_glm
plot(bayes_glm)
```

We also fitted a Bayesian logistic regression model with lasso regularization priors. The coefficients mean estimates turned out to be very similar to the frequentistic logistic regression model.


## Plotting marginal effects (logodds scale)
```{r, fig.show = "hide", warning = FALSE}
plots <- plot(marginal_effects(bayes_glm, 
                               effects = c("distance_km", "windspeed_avg_h", 
                                           "airpres","lightnings_hour_f", "sunshine_dur_min", 
                                           "windspeed_avg_h", "global_rad_avg_h",
                                           "precip", "lightnings_hour_n", "rel_humid")))
```
```{r fig.height = 10}
grid.arrange(plots$distance_km, plots$windspeed_avg_h, plots$airpres, 
             plots$lightnings_hour_f, plots$sunshine_dur_min, plots$windspeed_avg_h,
             plots$global_rad_avg_h, plots$precip, plots$lightnings_hour_n, plots$rel_humid,
             ncol = 2)
```


## What could be done in the future
* Try to rewrite the code less messy
* Use dimension reduction techniques like PCA to have less covariates and then regress the outcome on them
* Not categorize the delay time and try to transform it / use more robust methods
* Use random effects in the Bayesian model for airlines and airplanes
* Analyze the delays of landing flights by also getting the weather data of the destination from where they came from
* Use more complex models (boosting, random forests, neural networks) to improve predicitive performance (at the cost of interpretability)
